{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to EITprocessing","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to the documentation of the ALIVE software tool designed to load, analyze, and extract parameters from Electrical Impedance Tomography (EIT) data. This software was designed by a joined effort of the Rotterdam Advanced Respiratory Care research group (ROTARC) of the Intensive Care of the Erasmus Medical Center and the Netherlands e-Science center. Grant ID: NLESC.OEC.2022.002</p> <p>EIT is a bedside non-invasive lung imaging tool: it continuously and real-time visualizes changes in lung volume. Our software tool serves as a comprehensive solution for handling EIT data from multiple leading manufacturers, including Sentec, Dr\u00e4ger, and Timpel.</p> <p>The software tool includes a back-end for researchers that are familair with programming eitprocessing and also a user-friendly dashboard eit_dash for clinical researchers allowing to quickly import datasets from various formats and sources and perform processing and analysis. This documentation page concerns eitprocessing.</p> <p>Our tool offers robust analysis features. From basic filters to advanced signal processing techniques, you can extract meaningful parameters from your EIT data. With our dashboard we aim to provide default analysis pipelines and many opportunities for customization according to the user needs. Visualizations and interactive graphs make it easy to interpret the results and understand the underlying physiological processes.</p> <p>It is important to note that the software tool is a work in progress, so not all fuctionalities are available yet. If you would like to contribute to coding you can reach out to us.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To start using our software you can you use the installation guide to set up the software on your system. Once installed, you can load your first dataset and explore the basic features. We are committed to supporting your journey with EIT data analysis and extraction. If you encounter any issues or have questions you can put a pull request via github or emailadres.</p>"},{"location":"basic_example/","title":"Basic example","text":"<p>Under construction</p>"},{"location":"code_of_conduct_doc/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct_doc/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"code_of_conduct_doc/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct_doc/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"code_of_conduct_doc/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"code_of_conduct_doc/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at d.bodor@esciencecenter.nl. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"code_of_conduct_doc/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"contributing_doc/","title":"Contributing guidelines","text":"<p>We welcome any kind of contribution to our software, from simple comment or question to a full fledged pull request. Please read and follow our Code of Conduct.</p> <p>A contribution can be one of the following cases:</p> <ol> <li>you have a question;</li> <li>you think you may have found a bug (including unexpected behavior);</li> <li>you want to make some kind of change to the code base (e.g. to fix a bug, to add a new feature, to update documentation);</li> <li>you want to make a new release of the code base.</li> </ol> <p>The sections below outline the steps in each case.</p>"},{"location":"contributing_doc/#you-have-a-question","title":"You have a question","text":"<ol> <li>use the search functionality here to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, make a new issue;</li> <li>apply the \"Question\" label; apply other labels when relevant.</li> </ol>"},{"location":"contributing_doc/#you-think-you-may-have-found-a-bug","title":"You think you may have found a bug","text":"<ol> <li>use the search functionality here to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, make a new issue, making sure to provide enough information to the rest of the community to understand the cause and context of the problem. Depending on the issue, you may want to include:</li> <li>the SHA hashcode of the commit that is causing your problem;</li> <li>some identifying information (name and version number) for dependencies you're using;</li> <li>information about the operating system;</li> <li>apply relevant labels to the newly created issue.</li> </ol>"},{"location":"contributing_doc/#you-want-to-make-some-kind-of-change-to-the-code-base","title":"You want to make some kind of change to the code base","text":"<p>We welcome all contributions to this open-source project, as long as they follow our code of conduct.</p> <p>Please read out developers documentation if you are interested in contributing to the code base</p>"},{"location":"installation/","title":"Installation","text":"<p>It is advised to install eitprocessing in a dedicated virtual environment. See e.g. Install packages in a virtual environment using pip and venv or Getting started with conda.</p>"},{"location":"installation/#install-from-pypi","title":"Install from PyPi","text":"<p>eitprocessing can be installed from PyPi as follows:</p> <pre><code>pip install eitprocessing\n</code></pre>"},{"location":"installation/#developer-install","title":"Developer install","text":"<p>For full developer options (testing, etc):</p> <pre><code>git clone git@github.com:EIT-ALIVE/eitprocessing.git\ncd eitprocessing\npip install -e \".[dev]\"\n</code></pre>"},{"location":"license_doc/","title":"License","text":"<p>Apache License Version 2.0, January 2004 http://www.apache.org/licenses/</p> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li>Definitions.</li> </ol> <p>\"License\" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    \"control\" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity    exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, \"submitted\"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.</p> <ol> <li> <p>Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:</p> </li> </ol> <p>(a) You must give any other recipients of the Work or          Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices          stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works          that You distribute, all copyright, patent, trademark, and          attribution notices from the Source form of the Work,          excluding those notices that do not pertain to any part of          the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its          distribution, then any Derivative Works that You distribute must          include a readable copy of the attribution notices contained          within such NOTICE file, excluding those notices that do not          pertain to any part of the Derivative Works, in at least one          of the following places: within a NOTICE text file distributed          as part of the Derivative Works; within the Source form or          documentation, if provided along with the Derivative Works; or,          within a display generated by the Derivative Works, if and          wherever such third-party notices normally appear. The contents          of the NOTICE file are for informational purposes only and          do not modify the License. You may add Your own attribution          notices within Derivative Works that You distribute, alongside          or as an addendum to the NOTICE text from the Work, provided          that such additional attribution notices cannot be construed          as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.</p> <ol> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <p>To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"{}\" replaced with your own identifying information. (Don't include the brackets!)  The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives.</p> <p>Copyright [yyy][name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <p>http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"team/","title":"Our Team","text":""},{"location":"team/#escience-center","title":"eScience Center","text":"<ul> <li>Dani Bodor, Lead RSE</li> <li>Walter Baccinelli, RSE</li> <li>Pablo Lopez-Tarifa, Programme Manager</li> </ul>"},{"location":"team/#erasmus-medical-center-rotterdam","title":"Erasmus Medical Center Rotterdam","text":"<ul> <li>Annemijn H. Jonkman, Lead Applicant</li> <li>Peter Somhorst</li> <li>Juliette Francovich</li> <li>Jantine Wisse</li> </ul>"},{"location":"api/categories/","title":"Categories","text":""},{"location":"api/categories/#eitprocessing.categories.Category","title":"eitprocessing.categories.Category","text":"<pre><code>Category(name: str, parent: Self | None = None)\n</code></pre> <p>Data category indicating what type of information is saved in an object.</p> <p>Categories are nested, where more specific categories are nested inside more general categories. The root category is simply named 'category'. Categories have a unique name within the entire tree.</p> <p>To check the existence of a category with name  within a category tree, either as subcategory or subsub(...)category, <code>category.has_subcategory(\"&lt;name&gt;\")</code> can be used. The keyword <code>in</code> can be used as a shorthand. <p>Example: <pre><code>&gt;&gt;&gt; \"tea\" in category  # is the same as:\nTrue\n&gt;&gt;&gt; category.has_subcategory(\"tea\")\nTrue\n</code></pre></p> <p>To select a subcategory, <code>category[\"&lt;name&gt;\"]</code> can be used. You can select multiple categories at once. This will create a new tree with a temporary root, containing only the selected categories.</p> <p>Example: <pre><code>&gt;&gt;&gt; foobar = categories[\"foo\", \"bar\"]\n&gt;&gt;&gt; print(foobar)\nCategory('/temporary root')\n&gt;&gt;&gt; print(foobar.children)\n(Category('/temporary root/foo'), Category('/temporary root/bar'))\n</code></pre></p> <p>Categories can be hand-crafted, created from a dictionary or a YAML string. See <code>anytree.DictionaryImporter</code> documentation for more info on the dictionary format. anytree documentation on YAML import/export shows the relevant structure of a normal YAML string.</p> <p>Categories also supports a compact YAML format, where each category containing a subcategory is a sequence. Categories without subcategories are strings in those sequences.</p> <pre><code>root:\n- sub 1 (without subcategories)\n- sub 2 (with subcategories):\n  - sub a (without subcategories)\n</code></pre> <p>Categories are read-only by default, as they should not be edited by the end-user during runtime. Consider editing the config file instead.</p> <p>Each type of data that is attached to an eitprocessing object should be categorized as one of the available types of data. This allows algorithms to check whether it can apply itself to the provided data, preventing misuse of algorithms.</p> <p>Example: <pre><code>&gt;&gt;&gt; categories = get_default_categories()\n&gt;&gt;&gt; print(categories)\nCategory('/category')\n&gt;&gt;&gt; print(\"pressure\" in categories)\nTrue\n&gt;&gt;&gt; categories[\"pressure\"]\nCategory('/category/physical measurement/pressure')\n</code></pre></p>"},{"location":"api/categories/#eitprocessing.categories.Category.has_subcategory","title":"has_subcategory","text":"<pre><code>has_subcategory(subcategory: str) -&gt; bool\n</code></pre> <p>Check whether this category contains a subcategory.</p> <p>Returns True if the category and subcategory both exist. Returns False if the category exists, but the subcategory does not. Raises a ValueError</p> Attr <p>category: the category to be checked as an ancestor of the subcategory. This category should exist. subcategory: the subcategory to be checked as a descendent of the category.</p> RETURNS DESCRIPTION <code>bool</code> <p>whether subcategory exists as a descendent of category.</p> <p> TYPE: <code>bool</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if category does not exist.</p>"},{"location":"api/categories/#eitprocessing.categories.Category.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(string: str) -&gt; Self\n</code></pre> <p>Load categories from YAML file.</p>"},{"location":"api/categories/#eitprocessing.categories.Category.from_compact_yaml","title":"from_compact_yaml  <code>classmethod</code>","text":"<pre><code>from_compact_yaml(string: str) -&gt; Self\n</code></pre> <p>Load categories from compact YAML file.</p>"},{"location":"api/categories/#eitprocessing.categories.Category.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(dictionary: dict) -&gt; Self\n</code></pre> <p>Create categories from dictionary.</p>"},{"location":"api/datacontainers/","title":"Data containers","text":""},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence","title":"eitprocessing.datahandling.sequence.Sequence  <code>dataclass</code>","text":"<pre><code>Sequence(\n    label: str | None = None,\n    name: str | None = None,\n    description: str = \"\",\n    eit_data: DataCollection[EITData] = (lambda: DataCollection(EITData))(),\n    continuous_data: DataCollection[ContinuousData] = (\n        lambda: DataCollection(ContinuousData)\n    )(),\n    sparse_data: DataCollection[SparseData] = (\n        lambda: DataCollection(SparseData)\n    )(),\n    interval_data: DataCollection[IntervalData] = (\n        lambda: DataCollection(IntervalData)\n    )(),\n)\n</code></pre> <p>Sequence of timepoints containing respiratory data.</p> <p>A Sequence object is a representation of data points over time. These data can consist of any combination of EIT frames (<code>EITData</code>), waveform data (<code>ContinuousData</code>) from different sources, or individual events (<code>SparseData</code>) occurring at any given timepoint. A Sequence can consist of an entire measurement, a section of a measurement, a single breath, or even a portion of a breath. A Sequence can consist of multiple sets of each type of data from the same time-points or can be a single measurement from just one source.</p> <p>A Sequence can be split up into separate sections of a measurement or multiple (similar) Sequence objects can be merged together to form a single Sequence.</p> PARAMETER DESCRIPTION <code>label</code> <p>Computer readable naming of the instance.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>Human readable naming of the instance.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>Human readable extended description of the data.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>eit_data</code> <p>Collection of one or more sets of EIT data frames.</p> <p> TYPE: <code>DataCollection[EITData]</code> DEFAULT: <code>(lambda: DataCollection(EITData))()</code> </p> <code>continuous_data</code> <p>Collection of one or more sets of continuous data points.</p> <p> TYPE: <code>DataCollection[ContinuousData]</code> DEFAULT: <code>(lambda: DataCollection(ContinuousData))()</code> </p> <code>sparse_data</code> <p>Collection of one or more sets of individual data points.</p> <p> TYPE: <code>DataCollection[SparseData]</code> DEFAULT: <code>(lambda: DataCollection(SparseData))()</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.time","title":"time  <code>property</code>","text":"<pre><code>time: ndarray\n</code></pre> <p>Time axis from either EITData or ContinuousData.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.concatenate","title":"concatenate  <code>classmethod</code>","text":"<pre><code>concatenate(a: Sequence, b: Sequence, newlabel: str | None = None) -&gt; Sequence\n</code></pre> <p>Create a merge of two Sequence objects.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    start_inclusive: bool = True,\n    end_inclusive: bool = False,\n    label: str | None = None,\n    name: str | None = None,\n    description: str = \"\",\n) -&gt; Self\n</code></pre> <p>Return a sliced version of the Sequence.</p> <p>See <code>SelectByTime.select_by_time()</code>.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sequence.Sequence.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData","title":"eitprocessing.datahandling.eitdata.EITData  <code>dataclass</code>","text":"<pre><code>EITData(\n    path: str | Path | list[Path | str],\n    nframes: int,\n    time: ndarray,\n    sample_frequency: float,\n    vendor: Vendor,\n    label: str | None = None,\n    description: str = \"\",\n    name: str | None = None,\n    *,\n    pixel_impedance: ndarray\n)\n</code></pre> <p>Container for EIT impedance data.</p> <p>This class holds the pixel impedance from an EIT measurement, as well as metadata describing the measurement. The class is meant to hold data from (part of) a singular continuous measurement.</p> <p>This class can't be initialized directly. Instead, use <code>load_eit_data(&lt;path&gt;, vendor=&lt;vendor&gt;)</code> to load data from disk.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path of list of paths of the source from which data was derived.</p> <p> TYPE: <code>str | Path | list[Path | str]</code> </p> <code>nframes</code> <p>Number of frames.</p> <p> TYPE: <code>int</code> </p> <code>time</code> <p>The time of each frame (since start measurement).</p> <p> TYPE: <code>ndarray</code> </p> <code>sample_frequency</code> <p>The (average) frequency at which the frames are collected, in Hz.</p> <p> TYPE: <code>float</code> </p> <code>vendor</code> <p>The vendor of the device the data was collected with.</p> <p> TYPE: <code>Vendor</code> </p> <code>label</code> <p>Computer readable label identifying this dataset.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>Human readable name for the data.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>pixel_impedance</code> <p>Impedance values for each pixel at each frame.</p> <p> TYPE: <code>ndarray</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.framerate","title":"framerate  <code>property</code>","text":"<pre><code>framerate: float\n</code></pre> <p>Deprecated alias to <code>sample_frequency</code>.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.ensure_path_list","title":"ensure_path_list  <code>staticmethod</code>","text":"<pre><code>ensure_path_list(path: str | Path | list[str | Path]) -&gt; list[Path]\n</code></pre> <p>Return the path or paths as a list.</p> <p>The path of any EITData object can be a single str/Path or a list of str/Path objects. This method returns a list of Path objects given either a str/Path or list of str/Paths.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.calculate_global_impedance","title":"calculate_global_impedance","text":"<pre><code>calculate_global_impedance() -&gt; ndarray\n</code></pre> <p>Return the global impedance, i.e. the sum of all included pixels at each frame.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    start_inclusive: bool = False,\n    end_inclusive: bool = False,\n    label: str | None = None,\n) -&gt; Self\n</code></pre> <p>Get a shortened copy of the object, starting from start_time and ending at end_time.</p> <p>Given a start and end time stamp (i.e. its value, not its index), return a slice of the original object, which must contain a time axis.</p> PARAMETER DESCRIPTION <code>start_time</code> <p>first time point to include. Defaults to first frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>end_time</code> <p>last time point. Defaults to last frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>start_inclusive</code> <p><code>True</code>), end_inclusive (default <code>False</code>): these arguments control the behavior if the given time stamp does not match exactly with an existing time stamp of the input. if <code>True</code>: the given time stamp will be inside the sliced object. if <code>False</code>: the given time stamp will be outside the sliced object.</p> <p> TYPE: <code>default</code> DEFAULT: <code>False</code> </p> <code>label</code> <p>Description. Defaults to None, which will create a label based on the original object label and the frames by which it is sliced.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>if <code>self</code> does not contain a <code>time</code> attribute.</p> <code>ValueError</code> <p>if time stamps are not sorted.</p> RETURNS DESCRIPTION <code>Self</code> <p>A shortened copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.eitdata.EITData.deepcopy","title":"deepcopy","text":"<pre><code>deepcopy() -&gt; Self\n</code></pre> <p>Return a deep copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData","title":"eitprocessing.datahandling.continuousdata.ContinuousData  <code>dataclass</code>","text":"<pre><code>ContinuousData(\n    label: str,\n    name: str,\n    unit: str,\n    category: str,\n    description: str = \"\",\n    parameters: dict[str, Any] = dict(),\n    derived_from: Any | list[Any] = list(),\n    *,\n    time: ndarray,\n    values: ndarray,\n    sample_frequency: float | None = None\n)\n</code></pre> <p>Container for data with a continuous time axis.</p> <p>Continuous data is assumed to be sequential (i.e. a single data point at each time point, sorted by time) and continuously measured/created at a fixed sampling frequency. However, a fixed interval between consecutive time points is not enforced to account for floating point arithmetic, devices with imperfect sampling frequencies, and other sources of variation.</p> PARAMETER DESCRIPTION <code>label</code> <p>Computer readable naming of the instance.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Human readable naming of the instance.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>Unit of the data, if applicable.</p> <p> TYPE: <code>str</code> </p> <code>category</code> <p>Category the data falls into, e.g. 'airway pressure'.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>Human readable extended description of the data.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>parameters</code> <p>Parameters used to derive this data.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p> <code>derived_from</code> <p>Traceback of intermediates from which the current data was derived.</p> <p> TYPE: <code>Any | list[Any]</code> DEFAULT: <code>list()</code> </p> <code>values</code> <p>Data points.</p> <p> TYPE: <code>ndarray</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.locked","title":"locked  <code>property</code>","text":"<pre><code>locked: bool\n</code></pre> <p>Return whether the values attribute is locked.</p> <p>See lock().</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.loaded","title":"loaded  <code>property</code>","text":"<pre><code>loaded: bool\n</code></pre> <p>Return whether the data was loaded from disk, or derived from elsewhere.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.copy","title":"copy","text":"<pre><code>copy(\n    label: str,\n    *,\n    name: str | None = None,\n    unit: str | None = None,\n    description: str | None = None,\n    parameters: dict | None = None\n) -&gt; Self\n</code></pre> <p>Create a copy.</p> <p>Whenever data is altered, it should probably be copied first. The alterations should then be made in the copy.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.derive","title":"derive","text":"<pre><code>derive(\n    label: str, function: Callable, func_args: dict | None = None, **kwargs\n) -&gt; Self\n</code></pre> <p>Create a copy deriving data from values attribute.</p> PARAMETER DESCRIPTION <code>label</code> <p>New label for the derived object.</p> <p> TYPE: <code>str</code> </p> <code>function</code> <p>Function that takes the values and returns the derived values.</p> <p> TYPE: <code>Callable</code> </p> <code>func_args</code> <p>Arguments to pass to function, if any.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Values for changed attributes of derived object.</p> <p> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>def convert_data(x, add=None, subtract=None, multiply=None, divide=None):\n    if add:\n        x += add\n    if subtract:\n        x -= subtract\n    if multiply:\n        x *= multiply\n    if divide:\n        x /= divide\n    return x\n\n\ndata = ContinuousData(\n    name=\"Lung volume (in mL)\", label=\"volume_mL\", unit=\"mL\", category=\"volume\", values=some_loaded_data\n)\nderived = data.derive(\"volume_L\", convert_data, {\"divide\": 1000}, name=\"Lung volume (in L)\", unit=\"L\")\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.lock","title":"lock","text":"<pre><code>lock(*attr: str) -&gt; None\n</code></pre> <p>Lock attributes, essentially rendering them read-only.</p> <p>Locked attributes cannot be overwritten. Attributes can be unlocked using <code>unlock()</code>.</p> PARAMETER DESCRIPTION <code>*attr</code> <p>any number of attributes can be passed here, all of which will be locked. Defaults to \"values\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>()</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # lock the `values` attribute of `data`\n&gt;&gt;&gt; data.lock()\n&gt;&gt;&gt; data.values = [1, 2, 3] # will result in an AttributeError\n&gt;&gt;&gt; data.values[0] = 1      # will result in a RuntimeError\n</code></pre>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.unlock","title":"unlock","text":"<pre><code>unlock(*attr: str) -&gt; None\n</code></pre> <p>Unlock attributes, rendering them editable.</p> <p>Locked attributes cannot be overwritten, but can be unlocked with this function to make them editable.</p> PARAMETER DESCRIPTION <code>*attr</code> <p>any number of attributes can be passed here, all of which will be unlocked. Defaults to \"values\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>()</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # lock the `values` attribute of `data`\n&gt;&gt;&gt; data.lock()\n&gt;&gt;&gt; data.values = [1, 2, 3] # will result in an AttributeError\n&gt;&gt;&gt; data.values[0] = 1      # will result in a RuntimeError\n&gt;&gt;&gt; data.unlock()\n&gt;&gt;&gt; data.values = [1, 2, 3]\n&gt;&gt;&gt; print(data.values)\n[1,2,3]\n&gt;&gt;&gt; data.values[0] = 1      # will result in a RuntimeError\n&gt;&gt;&gt; print(data.values)\n1\n</code></pre>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    start_inclusive: bool = False,\n    end_inclusive: bool = False,\n    label: str | None = None,\n) -&gt; Self\n</code></pre> <p>Get a shortened copy of the object, starting from start_time and ending at end_time.</p> <p>Given a start and end time stamp (i.e. its value, not its index), return a slice of the original object, which must contain a time axis.</p> PARAMETER DESCRIPTION <code>start_time</code> <p>first time point to include. Defaults to first frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>end_time</code> <p>last time point. Defaults to last frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>start_inclusive</code> <p><code>True</code>), end_inclusive (default <code>False</code>): these arguments control the behavior if the given time stamp does not match exactly with an existing time stamp of the input. if <code>True</code>: the given time stamp will be inside the sliced object. if <code>False</code>: the given time stamp will be outside the sliced object.</p> <p> TYPE: <code>default</code> DEFAULT: <code>False</code> </p> <code>label</code> <p>Description. Defaults to None, which will create a label based on the original object label and the frames by which it is sliced.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>if <code>self</code> does not contain a <code>time</code> attribute.</p> <code>ValueError</code> <p>if time stamps are not sorted.</p> RETURNS DESCRIPTION <code>Self</code> <p>A shortened copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.continuousdata.ContinuousData.deepcopy","title":"deepcopy","text":"<pre><code>deepcopy() -&gt; Self\n</code></pre> <p>Return a deep copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData","title":"eitprocessing.datahandling.sparsedata.SparseData  <code>dataclass</code>","text":"<pre><code>SparseData(\n    label: str,\n    name: str,\n    unit: str | None,\n    category: str,\n    time: ndarray,\n    description: str = \"\",\n    parameters: dict[str, Any] = dict(),\n    derived_from: list[Any] = list(),\n    values: Any | None = None,\n)\n</code></pre> <p>Container for data related to individual time points.</p> <p>Sparse data is data for which the time points are not necessarily evenly spaced. Data can consist time-value pairs or only time points.</p> <p>Sparse data differs from interval data in that each data points is associated with a single time point rather than a time range.</p> <p>Examples are data points at end of inspiration/end of expiration (e.g. tidal volume, end-expiratoy lung impedance) or detected time points (e.g. QRS complexes).</p> PARAMETER DESCRIPTION <code>label</code> <p>Computer readable name.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Human readable name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>Unit of the data, if applicable.</p> <p> TYPE: <code>str | None</code> </p> <code>category</code> <p>Category the data falls into, e.g. 'detected r peak'.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>Human readable extended description of the data.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>parameters</code> <p>Parameters used to derive the data.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p> <code>derived_from</code> <p>Traceback of intermediates from which the current data was derived.</p> <p> TYPE: <code>list[Any]</code> DEFAULT: <code>list()</code> </p> <code>values</code> <p>List or array of values. These van be numeric data, text or Python objects.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.has_values","title":"has_values  <code>property</code>","text":"<pre><code>has_values: bool\n</code></pre> <p>True if the SparseData has values, False otherwise.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    start_inclusive: bool = False,\n    end_inclusive: bool = False,\n    label: str | None = None,\n) -&gt; Self\n</code></pre> <p>Get a shortened copy of the object, starting from start_time and ending at end_time.</p> <p>Given a start and end time stamp (i.e. its value, not its index), return a slice of the original object, which must contain a time axis.</p> PARAMETER DESCRIPTION <code>start_time</code> <p>first time point to include. Defaults to first frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>end_time</code> <p>last time point. Defaults to last frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>start_inclusive</code> <p><code>True</code>), end_inclusive (default <code>False</code>): these arguments control the behavior if the given time stamp does not match exactly with an existing time stamp of the input. if <code>True</code>: the given time stamp will be inside the sliced object. if <code>False</code>: the given time stamp will be outside the sliced object.</p> <p> TYPE: <code>default</code> DEFAULT: <code>False</code> </p> <code>label</code> <p>Description. Defaults to None, which will create a label based on the original object label and the frames by which it is sliced.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>if <code>self</code> does not contain a <code>time</code> attribute.</p> <code>ValueError</code> <p>if time stamps are not sorted.</p> RETURNS DESCRIPTION <code>Self</code> <p>A shortened copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.sparsedata.SparseData.deepcopy","title":"deepcopy","text":"<pre><code>deepcopy() -&gt; Self\n</code></pre> <p>Return a deep copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData","title":"eitprocessing.datahandling.intervaldata.IntervalData  <code>dataclass</code>","text":"<pre><code>IntervalData(\n    label: str,\n    name: str,\n    unit: str | None,\n    category: str,\n    intervals: list[Interval | tuple[float, float]],\n    values: list[Any] | None = None,\n    parameters: dict[str, Any] = dict(),\n    derived_from: list[Any] = list(),\n    description: str = \"\",\n    default_partial_inclusion: bool = False,\n)\n</code></pre> <p>Container for interval data existing over a period of time.</p> <p>Interval data is data that consists for a given time interval. Examples are a ventilator setting (e.g. end-expiratory pressure), the position of a patient, a maneuver (end-expiratory hold) being performed, detected periods in the data, etc.</p> <p>Interval data consists of a number of intervals that may or may not have values associated with them.</p> <p>Examples of IntervalData with associated values are certain ventilator settings (e.g. end-expiratory pressure) and the position of a patient. Examples of IntervalData without associated values are indicators of maneouvres (e.g. a breath hold) or detected occurences (e.g. a breath).</p> <p>Interval data can be selected by time through the <code>select_by_time(start_time, end_time)</code> method. Alternatively, <code>t[start_time:end_time]</code> can be used.</p> PARAMETER DESCRIPTION <code>label</code> <p>Computer readable label identifying this dataset.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Human readable name for the data.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The unit of the data, if applicable.</p> <p> TYPE: <code>str | None</code> </p> <code>category</code> <p>Category the data falls into, e.g. 'breath'.</p> <p> TYPE: <code>str</code> </p> <code>intervals</code> <p>A list of intervals (tuples containing a start time and end time).</p> <p> TYPE: <code>list[Interval | tuple[float, float]]</code> </p> <code>values</code> <p>An optional list of values associated with each interval.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>parameters</code> <p>Parameters used to derive the data.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p> <code>derived_from</code> <p>Traceback of intermediates from which the current data was derived.</p> <p> TYPE: <code>list[Any]</code> DEFAULT: <code>list()</code> </p> <code>description</code> <p>Extended human readible description of the data.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>default_partial_inclusion</code> <p>Whether to include a trimmed version of an interval when selecting data</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.has_values","title":"has_values  <code>property</code>","text":"<pre><code>has_values: bool\n</code></pre> <p>True if the IntervalData has values, False otherwise.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    partial_inclusion: bool | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>Create a new copy of the object, selecting data between start_time and end_time.</p> <p>This function returns a shortened copy of the object, containing data from the specified start_time to end_time.</p> <p>If <code>partial_inclusion</code> is set to <code>True</code>, any intervals that overlap with the start_time or end_time are included in the selection, and their times are adjusted to fit within the specified range. If <code>partial_inclusion</code> is <code>False</code>, intervals that overlap the start or end times are excluded from the selection.</p> <p>For example: - Set <code>partial_inclusion</code> to <code>True</code> for cases like \"set_driving_pressure\" where you want to include settings that were active before the start_time. - Set <code>partial_inclusion</code> to <code>False</code> for cases like \"detected_breaths\" where you want to exclude partial data that doesn't fully fit within the time range.</p> <p>Note that the end_time is always included in the selection if it is present in the original object.</p> PARAMETER DESCRIPTION <code>start_time</code> <p>The earliest time point to include in the copy.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>end_time</code> <p>The latest time point to include in the copy.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>partial_inclusion</code> <p>Whether to include intervals that overlap with the start_time or end_time.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>newlabel</code> <p>A new label for the copied object.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.intervaldata.IntervalData.deepcopy","title":"deepcopy","text":"<pre><code>deepcopy() -&gt; Self\n</code></pre> <p>Return a deep copy of the object.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection","title":"eitprocessing.datahandling.datacollection.DataCollection","text":"<pre><code>DataCollection(data_type: type[V], *args, **kwargs)\n</code></pre> <p>A collection of a single type of data with unique labels.</p> <p>A DataCollection functions largely as a dictionary, but requires a data_type argument, which must be one of the data containers existing in this package. When adding an item to the collection, the type of the value must match the data_type of the collection. Furthermore, the key has to match the attribute 'label' attached to the value.</p> <p>The convenience method <code>add()</code> adds an item by setting the key to <code>value.label</code>.</p> PARAMETER DESCRIPTION <code>data_type</code> <p>the data container stored in this collection.</p> <p> TYPE: <code>type[V]</code> </p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.add","title":"add","text":"<pre><code>add(*item: V, overwrite: bool = False) -&gt; None\n</code></pre> <p>Add one or multiple item(s) to the collection using the item label as the key.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.get_loaded_data","title":"get_loaded_data","text":"<pre><code>get_loaded_data() -&gt; dict[str, V]\n</code></pre> <p>Return all data that was directly loaded from disk.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.get_data_derived_from","title":"get_data_derived_from","text":"<pre><code>get_data_derived_from(obj: V) -&gt; dict[str, V]\n</code></pre> <p>Return all data that was derived from a specific source.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.get_derived_data","title":"get_derived_data","text":"<pre><code>get_derived_data() -&gt; dict[str, V]\n</code></pre> <p>Return all data that was derived from any source.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.concatenate","title":"concatenate","text":"<pre><code>concatenate(other: Self) -&gt; Self\n</code></pre> <p>Concatenate this collection with an equivalent collection.</p> <p>Each item of self of concatenated with the item of other with the same key.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None,\n    end_time: float | None,\n    start_inclusive: bool = True,\n    end_inclusive: bool = False,\n) -&gt; DataCollection\n</code></pre> <p>Return a DataCollection containing sliced copies of the items.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.datacollection.DataCollection.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.breath.Breath","title":"eitprocessing.datahandling.breath.Breath  <code>dataclass</code>","text":"<pre><code>Breath(start_time: float, middle_time: float, end_time: float)\n</code></pre> <p>Represents a breath with a start, middle and end time.</p>"},{"location":"api/datacontainers/#eitprocessing.datahandling.event.Event","title":"eitprocessing.datahandling.event.Event  <code>dataclass</code>","text":"<pre><code>Event(marker: int, text: str)\n</code></pre> <p>Single time point event registered during an EIT measurement.</p>"},{"location":"api/features/","title":"Feature extraction","text":""},{"location":"api/features/#eitprocessing.features.breath_detection.BreathDetection","title":"eitprocessing.features.breath_detection.BreathDetection  <code>dataclass</code>","text":"<pre><code>BreathDetection(\n    *,\n    minimum_duration: float = 2 / 3,\n    averaging_window_duration: float = 15,\n    averaging_window_function: Callable[[int], ArrayLike] | None = blackman,\n    amplitude_cutoff_fraction: float | None = 0.25,\n    invalid_data_removal_window_length: float = 0.5,\n    invalid_data_removal_percentile: int = 5,\n    invalid_data_removal_multiplier: int = 4\n)\n</code></pre> <p>Algorithm for detecting breaths in data representing respiration.</p> <p>This algorithm detects the position of breaths in data by detecting valleys (local minimum values) and peaks (local maximum values) in data. BreathDetection has a default minimum duration of breaths to be detected. The minimum duration should be short enough to include the shortest expected breath in the data. The minimum duration is implemented as the minimum time between peaks and between valleys.</p> <p>Examples: <pre><code>&gt;&gt;&gt; bd = BreathDetection(minimum_duration=0.5)\n&gt;&gt;&gt; breaths = bd.find_breaths(\n...     sequency=seq,\n...     continuousdata_label=\"global_impedance_(raw)\"\n... )\n</code></pre></p> <pre><code>&gt;&gt;&gt; global_impedance = seq.continuous_data[\"global_impedance_(raw)\"]\n&gt;&gt;&gt; breaths = bd.find_breaths(continuous_data=global_impedance)\n</code></pre> PARAMETER DESCRIPTION <code>minimum_duration</code> <p>minimum expected duration of breaths, defaults to 2/3 of a second</p> <p> TYPE: <code>float</code> DEFAULT: <code>2 / 3</code> </p> <code>averaging_window_duration</code> <p>duration of window used for averaging the data, defaults to 15 seconds</p> <p> TYPE: <code>float</code> DEFAULT: <code>15</code> </p> <code>averaging_window_function</code> <p>function used to create a window for averaging the data, defaults to np.blackman</p> <p> TYPE: <code>Callable[[int], ArrayLike] | None</code> DEFAULT: <code>blackman</code> </p> <code>amplitude_cutoff_fraction</code> <p>fraction of the median amplitude below which breaths are removed, defaults to 0.25</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>0.25</code> </p> <code>invalid_data_removal_window_length</code> <p>window around invalid data in which breaths are removed, defaults to 0.5</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.5</code> </p> <code>invalid_data_removal_percentile</code> <p>the nth percentile of values used to remove outliers, defaults to 5</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>invalid_data_removal_multiplier</code> <p>the multiplier used to remove outliers, defaults to 4</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p>"},{"location":"api/features/#eitprocessing.features.breath_detection.BreathDetection.find_breaths","title":"find_breaths","text":"<pre><code>find_breaths(\n    continuous_data: ContinuousData,\n    result_label: str = \"breaths\",\n    sequence: Sequence | None = None,\n    store: bool | None = None,\n) -&gt; IntervalData\n</code></pre> <p>Find breaths based on peaks and valleys, removing edge cases and breaths during invalid data.</p> <p>First, it naively finds any peaks that are a certain distance apart and higher than the moving average, and similarly valleys that are a certain distance apart and below the moving average.</p> <p>Next, valleys at the start and end of the signal are removed to ensure the first and last valleys are actual valleys, and not just the start or end of the signal. Peaks before the first or after the last valley are removed, to ensure peaks always fall between two valleys.</p> <p>At this point, it is possible multiple peaks exist between two valleys. Lower peaks are removed leaving only the highest peak between two valleys. Similarly, multiple valleys between two peaks are reduced to only the lowest valley.</p> <p>As a last step, breaths with a low amplitude (the average between the inspiratory and expiratory amplitudes) are removed.</p> <p>Breaths are constructed as a valley-peak-valley combination, representing the start of inspiration, the end of inspiration/start of expiration, and end of expiration.</p> PARAMETER DESCRIPTION <code>continuous_data</code> <p>optional, a ContinuousData object that contains the data</p> <p> TYPE: <code>ContinuousData</code> </p> <code>result_label</code> <p>label of the returned IntervalData object, defaults to <code>'breaths'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'breaths'</code> </p> <code>sequence</code> <p>optional, Sequence that contains the object to detect breaths in, and/or to store the result in</p> <p> TYPE: <code>Sequence | None</code> DEFAULT: <code>None</code> </p> <code>store</code> <p>whether to store the result in the sequence, defaults to <code>True</code> if a Sequence if provided.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>IntervalData</code> <p>An IntervalData object containing Breath objects.</p>"},{"location":"api/features/#eitprocessing.features.pixel_breath.PixelBreath","title":"eitprocessing.features.pixel_breath.PixelBreath  <code>dataclass</code>","text":"<pre><code>PixelBreath(breath_detection_kwargs: dict = dict())\n</code></pre> <p>Algorithm for detecting timing of pixel breaths in pixel impedance data.</p> <p>This algorithm detects the position of start of inspiration, end of inspiration and end of expiration in pixel impedance data. It uses BreathDetection to find the global start and end of inspiration and expiration. These points are then used to find the start/end of pixel inspiration/expiration in pixel impedance data.</p> <p>Example: <pre><code>&gt;&gt;&gt; pi = PixelBreath()\n&gt;&gt;&gt; eit_data = sequence.eit_data['raw']\n&gt;&gt;&gt; continuous_data = sequence.continuous_data['global_impedance_(raw)']\n&gt;&gt;&gt; pixel_breaths = pi.find_pixel_breaths(eit_data, continuous_data, sequence)\n</code></pre></p> <p>breath_detection_kwargs (dict): A dictionary of keyword arguments for breath detection.     The available keyword arguments are:     minimum_duration: minimum expected duration of breaths, defaults to 2/3 of a second     averaging_window_duration: duration of window used for averaging the data, defaults to 15 seconds     averaging_window_function: function used to create a window for averaging the data, defaults to np.blackman     amplitude_cutoff_fraction: fraction of the median amplitude below which breaths are removed, defaults to 0.25     invalid_data_removal_window_length: window around invalid data in which breaths are removed, defaults to 0.5     invalid_data_removal_percentile: the nth percentile of values used to remove outliers, defaults to 5     invalid_data_removal_multiplier: the multiplier used to remove outliers, defaults to 4</p>"},{"location":"api/features/#eitprocessing.features.pixel_breath.PixelBreath.find_pixel_breaths","title":"find_pixel_breaths","text":"<pre><code>find_pixel_breaths(\n    eit_data: EITData,\n    continuous_data: ContinuousData,\n    sequence: Sequence | None = None,\n    store: bool | None = None,\n    result_label: str = \"pixel_breaths\",\n) -&gt; IntervalData\n</code></pre> <p>Find pixel breaths in the data.</p> <p>This method finds the pixel start/end of inspiration/expiration based on the start/end of inspiration/expiration as detected in the continuous data.</p> <p>If pixel impedance is in phase (within 180 degrees) with the continuous data, the start of breath of that pixel is defined as the local minimum between two end-inspiratory points in the continuous signal. The end of expiration of that pixel is defined as the local minimum between two consecutive end-inspiratory points in the continuous data. The end of inspiration of that pixel is defined as the local maximum between the start of inspiration and end of expiration of that pixel.</p> <p>If pixel impedance is out of phase with the continuous signal, the start of inspiration of that pixel is defined as the local maximum between two end-inspiration points in the continuous data. The end of expiration of that pixel is defined as the local maximum between two consecutive end-inspiratory points in the continuous data. The end of inspiration of that pixel is defined as the local minimum between the start of inspiration and end of expiration of that pixel.</p> <p>Pixel breaths are constructed as a valley-peak-valley combination, representing the start of inspiration, the end of inspiration/start of expiration, and end of expiration.</p> PARAMETER DESCRIPTION <code>eit_data</code> <p>EITData to apply the algorithm to</p> <p> TYPE: <code>EITData</code> </p> <code>continuous_data</code> <p>ContinuousData to use for global breath detection</p> <p> TYPE: <code>ContinuousData</code> </p> <code>result_label</code> <p>label of the returned IntervalData object, defaults to <code>'pixel_breaths'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'pixel_breaths'</code> </p> <code>sequence</code> <p>optional, Sequence that contains the object to detect pixel breaths in,</p> <p> TYPE: <code>Sequence | None</code> DEFAULT: <code>None</code> </p> <code>store</code> <p>whether to store the result in the sequence, defaults to <code>True</code> if a Sequence if provided.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>IntervalData</code> <p>An IntervalData object containing Breath objects.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If store is set to true but no sequence is provided.</p> <code>ValueError</code> <p>If the provided sequence is not an instance of the Sequence dataclass.</p>"},{"location":"api/features/#eitprocessing.features.moving_average.MovingAverage","title":"eitprocessing.features.moving_average.MovingAverage  <code>dataclass</code>","text":"<pre><code>MovingAverage(\n    window_size: int,\n    window_function: Callable | None = None,\n    padding_type: str = \"edge\",\n)\n</code></pre> <p>Algorithm for calculating the moving average of the data.</p> <p>This class provides a method for calculating of the moving average of a 1D signal by convolution with a window with a given size. If not window function is provided, all samples within that window contribute equally to the moving average. If a window function is provided, the samples are weighed according to the values in the window function.</p> <p>Before convolution the data is padded. The padding type is 'edge' by default. See <code>np.pad()</code> for more information. Padding adds values at the start and end with the first/last value, to more accurately determine the average at the boundaries of the data.</p> PARAMETER DESCRIPTION <code>window_size</code> <p>the number of data points in the averaging window. Should be odd; is increased by 1 if even.</p> <p> TYPE: <code>int</code> </p> <code>window_function</code> <p>window function, e.g. np.blackman.</p> <p> TYPE: <code>Callable | None</code> DEFAULT: <code>None</code> </p> <code>padding_type</code> <p>see <code>np.pad()</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'edge'</code> </p> RETURNS DESCRIPTION <p>np.ndarray: moving average of data with the same shape as <code>data</code>.</p>"},{"location":"api/features/#eitprocessing.features.moving_average.MovingAverage.apply","title":"apply","text":"<pre><code>apply(data: ndarray) -&gt; ndarray\n</code></pre> <p>Apply the moving average on the data.</p> PARAMETER DESCRIPTION <code>data</code> <p>input data as 1D array</p> <p> TYPE: <code>NDArray</code> </p>"},{"location":"api/filters/","title":"Filters","text":""},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.LowPassFilter","title":"eitprocessing.filters.butterworth_filters.LowPassFilter  <code>dataclass</code>","text":"<pre><code>LowPassFilter(\n    *,\n    filter_type: Literal[\"lowpass\"] = \"lowpass\",\n    cutoff_frequency: float | tuple[float],\n    order: int,\n    sample_frequency: float,\n    ignore_max_order: InitVar[bool] = False\n)\n</code></pre> <p>Low-pass Butterworth filter for filtering in the time domain.</p> <p><code>LowPassFilter</code> is a convenience class similar to <code>ButterworthFilter</code>, where the <code>filter_type</code> is set to \"lowpass\".</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.LowPassFilter.apply_filter","title":"apply_filter","text":"<pre><code>apply_filter(input_data: ArrayLike, axis: int = -1) -&gt; ndarray\n</code></pre> <p>Apply the filter to the input data.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>Data to be filtered. If the input data has more than one axis, the filter is applied to the last axis.</p> <p> TYPE: <code>ArrayLike</code> </p> <code>axis</code> <p>Data axis the filter should be applied to. This defaults to the last axis, assuming this to be the time axis of the input data.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>The filtered output with the same shape as the input data.</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.HighPassFilter","title":"eitprocessing.filters.butterworth_filters.HighPassFilter  <code>dataclass</code>","text":"<pre><code>HighPassFilter(\n    *,\n    filter_type: Literal[\"highpass\"] = \"highpass\",\n    cutoff_frequency: float | tuple[float],\n    order: int,\n    sample_frequency: float,\n    ignore_max_order: InitVar[bool] = False\n)\n</code></pre> <p>High-pass Butterworth filter for filtering in the time domain.</p> <p><code>HighPassFilter</code> is a convenience class similar to <code>ButterworthFilter</code>, where the <code>filter_type</code> is set to \"highpass\".</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.HighPassFilter.apply_filter","title":"apply_filter","text":"<pre><code>apply_filter(input_data: ArrayLike, axis: int = -1) -&gt; ndarray\n</code></pre> <p>Apply the filter to the input data.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>Data to be filtered. If the input data has more than one axis, the filter is applied to the last axis.</p> <p> TYPE: <code>ArrayLike</code> </p> <code>axis</code> <p>Data axis the filter should be applied to. This defaults to the last axis, assuming this to be the time axis of the input data.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>The filtered output with the same shape as the input data.</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.BandStopFilter","title":"eitprocessing.filters.butterworth_filters.BandStopFilter  <code>dataclass</code>","text":"<pre><code>BandStopFilter(\n    *,\n    filter_type: Literal[\"bandstop\"] = \"bandstop\",\n    cutoff_frequency: float | tuple[float],\n    order: int,\n    sample_frequency: float,\n    ignore_max_order: InitVar[bool] = False\n)\n</code></pre> <p>Band-stop Butterworth filter for filtering in the time domain.</p> <p><code>BandStopFilter</code> is a convenience class similar to <code>ButterworthFilter</code>, where the <code>filter_type</code> is set to \"bandstop\".</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.BandStopFilter.apply_filter","title":"apply_filter","text":"<pre><code>apply_filter(input_data: ArrayLike, axis: int = -1) -&gt; ndarray\n</code></pre> <p>Apply the filter to the input data.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>Data to be filtered. If the input data has more than one axis, the filter is applied to the last axis.</p> <p> TYPE: <code>ArrayLike</code> </p> <code>axis</code> <p>Data axis the filter should be applied to. This defaults to the last axis, assuming this to be the time axis of the input data.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>The filtered output with the same shape as the input data.</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.BandPassFilter","title":"eitprocessing.filters.butterworth_filters.BandPassFilter  <code>dataclass</code>","text":"<pre><code>BandPassFilter(\n    *,\n    filter_type: Literal[\"bandpass\"] = \"bandpass\",\n    cutoff_frequency: float | tuple[float],\n    order: int,\n    sample_frequency: float,\n    ignore_max_order: InitVar[bool] = False\n)\n</code></pre> <p>Band-pass Butterworth filter for filtering in the time domain.</p> <p><code>BandPassFilter</code> is a convenience class similar to <code>ButterworthFilter</code>, where the <code>filter_type</code> is set to \"bandpass\".</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.BandPassFilter.apply_filter","title":"apply_filter","text":"<pre><code>apply_filter(input_data: ArrayLike, axis: int = -1) -&gt; ndarray\n</code></pre> <p>Apply the filter to the input data.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>Data to be filtered. If the input data has more than one axis, the filter is applied to the last axis.</p> <p> TYPE: <code>ArrayLike</code> </p> <code>axis</code> <p>Data axis the filter should be applied to. This defaults to the last axis, assuming this to be the time axis of the input data.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>The filtered output with the same shape as the input data.</p>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.ButterworthFilter","title":"eitprocessing.filters.butterworth_filters.ButterworthFilter  <code>dataclass</code>","text":"<pre><code>ButterworthFilter(\n    *,\n    filter_type: Literal[\"lowpass\", \"highpass\", \"bandpass\", \"bandstop\"],\n    cutoff_frequency: float | tuple[float],\n    order: int,\n    sample_frequency: float,\n    ignore_max_order: InitVar[bool] = False\n)\n</code></pre> <p>Butterworth filter for filtering in the time domain.</p> <p>Generates a low-pass, high-pass, band-pass or band-stop digital Butterworth filter of order <code>order</code>. Filters are created using cascaded second-order sections representation, providing better stability compared to the traditionally used transfer function (numerator/denominator or b/a representation).</p> <p>The <code>apply_filter()</code> method applies the filter to the provided data using forward-backward filtering. This minimizes the phase shift, and effectively doubles the order of the filter.</p> <p><code>ButterworthFilter</code> is a wrapper of the <code>scipy.butter()</code> and <code>scipy.filtfilt()</code> functions:     - https://docs.scipy.org/doc/scipy-1.10.1/reference/generated/scipy.signal.butter.html     - https://docs.scipy.org/doc/scipy-1.10.1/reference/generated/scipy.signal.filtfilt.html</p> PARAMETER DESCRIPTION <code>filter_type</code> <p>The type of filter to create: a low pass, high pass, band pass or band stop filter.</p> <p> TYPE: <code>Literal['lowpass', 'highpass', 'bandpass', 'bandstop']</code> </p> <code>cutoff_frequency</code> <p>Cutoff frequency or frequencies (in Hz). For low pass or high pass filters, <code>cutoff_frequency</code> is a scalar. For band pass or band stop filters, <code>cutoff_frequency</code> is a sequence containing two frequencies.</p> <p> TYPE: <code>float | tuple[float]</code> </p> <code>order</code> <p>Order of the filter. The effective order size is twice the given order, due to forward-backward filtering. Higher orders improve the effectiveness of a filter, but can result in unstable or incorrect filtering.</p> <p> TYPE: <code>int</code> </p> <code>sample_frequency</code> <p>The sample frequency of the data to be filtered (in Hz).</p> <p> TYPE: <code>float</code> </p> <code>ignore_max_order</code> <p>Whether to raise an exception if the order is larger than the maximum of 10. Defaults to False.</p> <p> TYPE: <code>InitVar[bool]</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = np.arange(0, 100, 0.1)\n&gt;&gt;&gt; signal = np.sin(t) + 0.1 * np.sin(10 * t)\n&gt;&gt;&gt; lowpass_filter = ButterworthFilter(\n...     filter_type='lowpass',\n...     cutoff_frequenct=45,\n...     order=4,\n...     sample_frequency=250\n... )\n&gt;&gt;&gt; filtered_signal = lowpass_filter.apply_filter(signal)\n</code></pre>"},{"location":"api/filters/#eitprocessing.filters.butterworth_filters.ButterworthFilter.apply_filter","title":"apply_filter","text":"<pre><code>apply_filter(input_data: ArrayLike, axis: int = -1) -&gt; ndarray\n</code></pre> <p>Apply the filter to the input data.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>Data to be filtered. If the input data has more than one axis, the filter is applied to the last axis.</p> <p> TYPE: <code>ArrayLike</code> </p> <code>axis</code> <p>Data axis the filter should be applied to. This defaults to the last axis, assuming this to be the time axis of the input data.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>The filtered output with the same shape as the input data.</p>"},{"location":"api/loading/","title":"Loading functions","text":""},{"location":"api/loading/#eitprocessing.datahandling.loading.load_eit_data","title":"eitprocessing.datahandling.loading.load_eit_data","text":"<pre><code>load_eit_data(\n    path: str | Path | list[str | Path],\n    vendor: Vendor | str,\n    label: str | None = None,\n    name: str | None = None,\n    description: str = \"\",\n    sample_frequency: float | None = None,\n    first_frame: int = 0,\n    max_frames: int | None = None,\n) -&gt; Sequence\n</code></pre> <p>Load EIT data from path(s).</p> <p>Current limitations: - Dr\u00e4ger data is assumed to have a limited set of (Medibus) data. Newer additions that add data like pleural pressure are not yet supported.</p> PARAMETER DESCRIPTION <code>path</code> <p>relative or absolute path(s) to data file.</p> <p> TYPE: <code>str | Path | list[str | Path]</code> </p> <code>vendor</code> <p>vendor indicating the device used. Note: for load functions of specific vendors (e.g. <code>load_draeger_data</code>), this argument is defaulted to the correct vendor.</p> <p> TYPE: <code>Vendor | str</code> </p> <code>label</code> <p>short description of sequence for computer interpretation. Defaults to \"Sequence_\". <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>short description of sequence for human interpretation. Defaults to the same value as label.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>long description of sequence for human interpretation.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>sample_frequency</code> <p>sample frequency at which the data was recorded. No default for Draeger. Will be autodetected. Warns if autodetected differs from provided. Default for Timpel: 50 Default for Sentec: 50.2</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>first_frame</code> <p>index of first frame to load. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>max_frames</code> <p>maximum number of frames to load. The actual number of frames can be lower than this if this would surpass the final frame.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>is raised when there is no loading method for</p> RETURNS DESCRIPTION <code>Sequence</code> <p>a Sequence with the given label, name and description, containing the loaded data.</p> <p> TYPE: <code>Sequence</code> </p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(\n...     [\"path/to/file1\", \"path/to/file2\"],\n...     vendor=\"sentec\",\n...     label=\"initial_measurement\"\n... )\n&gt;&gt;&gt; pixel_impedance = sequence.eit_data[\"raw\"].pixel_impedance\n</code></pre></p>"},{"location":"api/mixins/","title":"Mixins","text":""},{"location":"api/mixins/#eitprocessing.datahandling.mixins.equality.Equivalence","title":"eitprocessing.datahandling.mixins.equality.Equivalence","text":"<p>Mixin class that adds an equality and equivalence check.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.equality.Equivalence.isequivalent","title":"isequivalent","text":"<pre><code>isequivalent(other: Self, raise_: bool = False) -&gt; bool\n</code></pre> <p>Test whether the data structure between two objects are equivalent.</p> <p>Equivalence, in this case means that objects are compatible e.g. to be merged. Data content can vary, but e.g. the category of data (e.g. airway pressure, flow, tidal volume) and unit, etc., must match.</p> PARAMETER DESCRIPTION <code>other</code> <p>object that will be compared to self.</p> <p> TYPE: <code>Self</code> </p> <code>raise_</code> <p>sets this method's behavior in case of non-equivalence. If True, an <code>EquivalenceError</code> is raised, otherwise <code>False</code> is returned.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>EquivalenceError</code> <p>if <code>raise_ == True</code> and the objects are not</p> RETURNS DESCRIPTION <code>bool</code> <p>bool describing result of equivalence comparison.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.SelectByIndex","title":"eitprocessing.datahandling.mixins.slicing.SelectByIndex","text":"<p>Adds slicing functionality to subclass by implementing <code>__getitem__</code>.</p> <p>Subclasses must implement a <code>_sliced_copy</code> function that defines what should happen when the object is sliced. This class ensures that when calling a slice between square brackets (as e.g. done for lists) then return the expected sliced object.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.SelectByIndex.select_by_index","title":"select_by_index","text":"<pre><code>select_by_index(\n    start: int | None = None,\n    end: int | None = None,\n    newlabel: str | None = None,\n) -&gt; Self\n</code></pre> <p>De facto implementation of the <code>__getitem__</code> function.</p> <p>This function can also be called directly to add a label to the sliced object. Otherwise a default label describing the slice and original object is attached.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.SelectByTime","title":"eitprocessing.datahandling.mixins.slicing.SelectByTime","text":"<p>Adds methods for slicing by time rather than index.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.SelectByTime.t","title":"t  <code>property</code>","text":"<pre><code>t: TimeIndexer\n</code></pre> <p>Slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.SelectByTime.select_by_time","title":"select_by_time","text":"<pre><code>select_by_time(\n    start_time: float | None = None,\n    end_time: float | None = None,\n    start_inclusive: bool = False,\n    end_inclusive: bool = False,\n    label: str | None = None,\n) -&gt; Self\n</code></pre> <p>Get a shortened copy of the object, starting from start_time and ending at end_time.</p> <p>Given a start and end time stamp (i.e. its value, not its index), return a slice of the original object, which must contain a time axis.</p> PARAMETER DESCRIPTION <code>start_time</code> <p>first time point to include. Defaults to first frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>end_time</code> <p>last time point. Defaults to last frame of sequence.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>start_inclusive</code> <p><code>True</code>), end_inclusive (default <code>False</code>): these arguments control the behavior if the given time stamp does not match exactly with an existing time stamp of the input. if <code>True</code>: the given time stamp will be inside the sliced object. if <code>False</code>: the given time stamp will be outside the sliced object.</p> <p> TYPE: <code>default</code> DEFAULT: <code>False</code> </p> <code>label</code> <p>Description. Defaults to None, which will create a label based on the original object label and the frames by which it is sliced.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>if <code>self</code> does not contain a <code>time</code> attribute.</p> <code>ValueError</code> <p>if time stamps are not sorted.</p> RETURNS DESCRIPTION <code>Self</code> <p>A shortened copy of the object.</p>"},{"location":"api/mixins/#eitprocessing.datahandling.mixins.slicing.TimeIndexer","title":"eitprocessing.datahandling.mixins.slicing.TimeIndexer  <code>dataclass</code>","text":"<pre><code>TimeIndexer(obj: T)\n</code></pre> <p>Helper class for slicing an object using the time axis instead of indices.</p> <p>Example: <pre><code>&gt;&gt;&gt; sequence = load_eit_data(&lt;path&gt;, ...)\n&gt;&gt;&gt; time_slice1 = sequence.t[tp_start:tp_end]\n&gt;&gt;&gt; time_slice2 = sequence.select_by_time(tp_start, tp_end)\n&gt;&gt;&gt; time_slice1 == time_slice2\nTrue\n</code></pre></p>"},{"location":"api/parameters/","title":"Parameters","text":""},{"location":"api/parameters/#eitprocessing.parameters.eeli.EELI","title":"eitprocessing.parameters.eeli.EELI  <code>dataclass</code>","text":"<pre><code>EELI(\n    method: Literal[\"breath_detection\"] = \"breath_detection\",\n    breath_detection_kwargs: dict = dict(),\n)\n</code></pre> <p>Compute the end-expiratory lung impedance (EELI) per breath.</p>"},{"location":"api/parameters/#eitprocessing.parameters.eeli.EELI.compute_parameter","title":"compute_parameter","text":"<pre><code>compute_parameter(\n    continuous_data: ContinuousData,\n    sequence: Sequence | None = None,\n    store: bool | None = None,\n    result_label: str = \"continuous_eelis\",\n) -&gt; SparseData\n</code></pre> <p>Compute the EELI for each breath in the impedance data.</p> <p>Example: <pre><code>&gt;&gt;&gt; global_impedance = sequence.continuous_data[\"global_impedance_(raw)\"]\n&gt;&gt;&gt; eeli_data = EELI().compute_parameter(global_impedance)\n</code></pre></p> PARAMETER DESCRIPTION <code>continuous_data</code> <p>a ContinuousData object containing impedance data.</p> <p> TYPE: <code>ContinuousData</code> </p> <code>sequence</code> <p>optional, Sequence to store the result in.</p> <p> TYPE: <code>Sequence | None</code> DEFAULT: <code>None</code> </p> <code>store</code> <p>whether to store the result in the sequence, defaults to <code>True</code> if a Sequence if provided.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>result_label</code> <p>label of the returned SparseData object, defaults to <code>'continuous_eelis'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'continuous_eelis'</code> </p> RETURNS DESCRIPTION <code>SparseData</code> <p>A SparseData object with the end-expiratory values of all breaths in the impedance data.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If store is set to true but no sequence is provided.</p> <code>ValueError</code> <p>If the provided sequence is not an instance of the Sequence dataclass.</p> <code>ValueError</code> <p>If tiv_method is not one of 'inspiratory', 'expiratory', or 'mean'.</p>"},{"location":"api/parameters/#eitprocessing.parameters.tidal_impedance_variation.TIV","title":"eitprocessing.parameters.tidal_impedance_variation.TIV  <code>dataclass</code>","text":"<pre><code>TIV(\n    method: Literal[\"extremes\"] = \"extremes\",\n    breath_detection_kwargs: dict = dict(),\n)\n</code></pre> <p>Compute the tidal impedance variation (TIV) per breath.</p>"},{"location":"api/parameters/#eitprocessing.parameters.tidal_impedance_variation.TIV.compute_parameter","title":"compute_parameter","text":"<pre><code>compute_parameter(data: ContinuousData | EITData) -&gt; NoReturn\n</code></pre> <p>Compute the tidal impedance variation per breath on either ContinuousData or EITData, depending on the input.</p> PARAMETER DESCRIPTION <code>data</code> <p>either continuous_data or eit_data to compute TIV on.</p> <p> TYPE: <code>ContinuousData | EITData</code> </p>"},{"location":"api/parameters/#eitprocessing.parameters.tidal_impedance_variation.TIV.compute_continuous_parameter","title":"compute_continuous_parameter","text":"<pre><code>compute_continuous_parameter(\n    continuous_data: ContinuousData,\n    tiv_method: Literal[\"inspiratory\", \"expiratory\", \"mean\"] = \"inspiratory\",\n    sequence: Sequence | None = None,\n    store: bool | None = None,\n    result_label: str = \"continuous_tivs\",\n) -&gt; SparseData\n</code></pre> <p>Compute the tidal impedance variation per breath.</p> PARAMETER DESCRIPTION <code>continuous_data</code> <p>The ContinuousData to compute the TIV on.</p> <p> TYPE: <code>ContinuousData</code> </p> <code>tiv_method</code> <p>The label of which part of the breath the TIV should be determined on (inspiratory, expiratory, or mean). Defaults to 'inspiratory'.</p> <p> TYPE: <code>Literal['inspiratory', 'expiratory', 'mean']</code> DEFAULT: <code>'inspiratory'</code> </p> <code>sequence</code> <p>optional, Sequence that contains the object to detect TIV on,</p> <p> TYPE: <code>Sequence | None</code> DEFAULT: <code>None</code> </p> <code>store</code> <p>whether to store the result in the sequence, defaults to <code>True</code> if a Sequence if provided.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>result_label</code> <p>label of the returned SparseData object, defaults to <code>'continuous_tivs'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'continuous_tivs'</code> </p> RETURNS DESCRIPTION <code>SparseData</code> <p>A SparseData object with the computed TIV values.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If store is set to true but no sequence is provided.</p> <code>ValueError</code> <p>If the provided sequence is not an instance of the Sequence dataclass.</p> <code>ValueError</code> <p>If tiv_method is not one of 'inspiratory', 'expiratory', or 'mean'.</p>"},{"location":"api/parameters/#eitprocessing.parameters.tidal_impedance_variation.TIV.compute_pixel_parameter","title":"compute_pixel_parameter","text":"<pre><code>compute_pixel_parameter(\n    eit_data: EITData,\n    continuous_data: ContinuousData,\n    sequence: Sequence,\n    tiv_method: Literal[\"inspiratory\", \"expiratory\", \"mean\"] = \"inspiratory\",\n    tiv_timing: Literal[\"pixel\", \"continuous\"] = \"pixel\",\n    store: bool | None = None,\n    result_label: str = \"pixel_tivs\",\n) -&gt; SparseData\n</code></pre> <p>Compute the tidal impedance variation per breath on pixel level.</p> PARAMETER DESCRIPTION <code>sequence</code> <p>The sequence containing the data.</p> <p> TYPE: <code>Sequence</code> </p> <code>eit_data</code> <p>The eit pixel level data to determine the TIV of.</p> <p> TYPE: <code>EITData</code> </p> <code>continuous_data</code> <p>The continuous data to determine the continuous data breaths or pixel level breaths.</p> <p> TYPE: <code>ContinuousData</code> </p> <code>tiv_method</code> <p>The label of which part of the breath the TIV should be determined on         (inspiratory, expiratory or mean). Defaults to 'inspiratory'.</p> <p> TYPE: <code>Literal['inspiratory', 'expiratory', 'mean']</code> DEFAULT: <code>'inspiratory'</code> </p> <code>tiv_timing</code> <p>The label of which timing should be used to compute the TIV, either based on breaths         detected in continuous data ('continuous') or based on pixel breaths ('pixel').         Defaults to 'pixel'.</p> <p> TYPE: <code>Literal['pixel', 'continuous']</code> DEFAULT: <code>'pixel'</code> </p> <code>result_label</code> <p>label of the returned IntervalData object, defaults to <code>'pixel_tivs'</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'pixel_tivs'</code> </p> <code>store</code> <p>whether to store the result in the sequence, defaults to <code>True</code> if a Sequence if provided.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SparseData</code> <p>A SparseData object with the computed TIV values.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If store is set to true but no sequence is provided.</p> <code>ValueError</code> <p>If the provided sequence is not an instance of the Sequence dataclass.</p> <code>ValueError</code> <p>If tiv_method is not one of 'inspiratory', 'expiratory', or 'mean'.</p> <code>ValueError</code> <p>If tiv_timing is not one of 'continuous' or 'pixel'.</p>"}]}